# ğŸ“˜ Document_Bassed_Exam_Preparation_Tool

**A lightweight AI-powered study assistant** that helps students revise faster â€”
ğŸ“„ **Upload a PDF**, ğŸ§  **Summarize key concepts**, and ğŸ¯ **Generate multiple-choice quiz questions** â€”
all locally using **Ollama** or other LLMs â€” *no cloud, no API costs!*

---

## âœ¨ Features

* ğŸ§¾ **PDF ingestion** using PyPDF2 â€” extracts clean text from any study document.
* ğŸ§  **Local summarization** powered by Ollama (works offline).
* ğŸ¯ **Automatic quiz generation** with multiple-choice questions (MCQs).
* ğŸ’» **Simple Flask web interface** â€” upload â†’ summarize â†’ quiz in 3 clicks.
* âš™ï¸ **Extensible backend** â€” supports Ollama, OpenAI, and Hugging Face models.
* ğŸ›¡ï¸ **Lightweight and private** â€” no vector DBs, no RAG, no external dependencies.

---

## ğŸ§± Tech Stack

| Component              | Technology Used                                    |
| ---------------------- | -------------------------------------------------- |
| **Frontend**           | HTML, CSS, Jinja2                                  |
| **Backend**            | Python (Flask)                                     |
| **AI Engine**          | Ollama (default), optionally OpenAI / Hugging Face |
| **PDF Processing**     | PyPDF2                                             |
| **Environment Config** | python-dotenv                                      |
| **Testing**            | pytest                                             |

---

## ğŸ“‚ Project Structure

```
Document_Bassed_Exam_Preparation_Tool/
â”œâ”€ app/
â”‚  â”œâ”€ __init__.py               # Flask app setup
â”‚  â”œâ”€ routes.py                 # Main routes (upload, summary, quiz)
â”‚  â”œâ”€ services/
â”‚  â”‚  â”œâ”€ pdf_loader.py          # PDF extraction logic
â”‚  â”‚  â”œâ”€ summarizer.py          # Summarization using LLMs
â”‚  â”‚  â””â”€ quiz_generator.py      # Quiz question generation logic
â”‚  â”œâ”€ templates/
â”‚  â”‚  â”œâ”€ base.html              # Common layout
â”‚  â”‚  â”œâ”€ index.html             # Upload UI
â”‚  â”‚  â”œâ”€ summary.html           # Summary page
â”‚  â”‚  â””â”€ quiz.html              # Quiz question interface
â”‚  â”œâ”€ static/
â”‚  â”‚  â”œâ”€ css/styles.css         # Styling
â”‚  â”‚  â””â”€ js/app.js              # Interactions
â”‚  â””â”€ utils/
â”‚     â””â”€ text_clean.py          # Cleans and normalizes extracted text
â”œâ”€ instance/
â”‚  â””â”€ uploads/                  # Uploaded PDFs (ignored by Git)
â”œâ”€ tests/                       # Unit tests
â”‚  â”œâ”€ test_pdf_loader.py
â”‚  â”œâ”€ test_summarizer.py
â”‚  â””â”€ test_quiz_generator.py
â”œâ”€ run.py                       # Flask entry point
â”œâ”€ requirements.txt             # Dependencies
â”œâ”€ .env.example                 # Example environment variables
â”œâ”€ .gitignore
â”œâ”€ setup_project.sh             # Script to auto-create structure
â””â”€ README.md
```

---

## âš™ï¸ Environment Setup

### ğŸª¶ 1ï¸âƒ£ Create `.env`

Copy `.env.example` â†’ `.env`, then update:

```bash
# For local Ollama (default backend)
LLM_BACKEND=ollama
OLLAMA_MODEL=llama3.2:3b

# Optional (for OpenAI or HF use)
OPENAI_API_KEY=your_key_here
HUGGINGFACE_API_KEY=your_key_here

# Flask config
FLASK_ENV=development
SECRET_KEY=your_secret_here
```

---

## ğŸš€ Run Locally

### 1ï¸âƒ£ Clone the repo

```bash
git clone https://github.com/<your-username>/Document_Bassed_Exam_Preparation_Tool.git
cd Document_Bassed_Exam_Preparation_Tool
```

### 2ï¸âƒ£ Create and activate a virtual environment

```bash
python -m venv .venv
source .venv/bin/activate       # (Windows: .venv\Scripts\activate)
```

### 3ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Start Flask app

```bash
python run.py
```

Now open your browser at ğŸ‘‰ **[http://127.0.0.1:5000](http://127.0.0.1:5000)**

---

## ğŸ’¡ Using Ollama (Offline Mode)

### ğŸ”¹ Install Ollama

Download and install from â†’ [https://ollama.com/download](https://ollama.com/download)

### ğŸ”¹ Pull a local model

Choose a small model (works even on CPU):

```bash
ollama pull llama3.2:3b
```

### ğŸ”¹ Start your app

```bash
python run.py
```

Now the AI runs entirely **offline** â€” no API keys or internet required ğŸ‰

---

## ğŸ§  How It Works

1. **Upload Document**
   â†’ PDF text is extracted using PyPDF2 and cleaned.

2. **Summarize Content**
   â†’ LLM (Ollama, OpenAI, or HF) condenses key ideas into bullet points.

3. **Generate Quiz Questions**
   â†’ AI creates structured MCQs (4 options, one correct answer).

4. **Review & Practice**
   â†’ Quiz page displays questions; â€œReveal Answerâ€ toggles show correct answers.

---

## ğŸ§© Supported Backends

| Backend          | Requires Key | Works Offline | Notes                                           |
| ---------------- | ------------ | ------------- | ----------------------------------------------- |
| **Ollama**       | âŒ No         | âœ… Yes         | Default and fastest local option                |
| **OpenAI**       | âœ… Yes        | âŒ No          | Use `gpt-4o-mini` etc.                          |
| **Hugging Face** | âœ… (free)     | âŒ No          | Works with `zephyr-7b-beta`, `phi-3-mini`, etc. |

Switch by setting `LLM_BACKEND` in `.env`.

---

## ğŸ§ª Running Tests

```bash
pytest
```

---

## ğŸ›  Troubleshooting

| Issue                 | Likely Cause                  | Fix                                            |
| --------------------- | ----------------------------- | ---------------------------------------------- |
| `Failed to summarize` | Model not found / no key      | Verify `.env` or Ollama model pulled           |
| `Extra data in JSON`  | Model added text outside JSON | Restart app; the parser now trims invalid text |
| `â€˜aâ€™ KeyError`        | Quiz options misformatted     | Fixed in latest version (normalizes keys)      |
| Slow response         | Using 7B+ model on CPU        | Use smaller model (`llama3.2:3b`)              |

---

## ğŸ§­ Roadmap (Phase 2 Ideas)

* ğŸ§¾ **Export quizzes** as CSV / JSON / PDF
* ğŸ§  **Adaptive difficulty** (easy/medium/hard)
* ğŸ§ **Scoring & practice mode**
* âš™ï¸ **Switch model backend from UI**
* ğŸ’¾ **Session memory** for previously uploaded documents

---
